# ğŸ“Š Multi-Agent Mutual Fund Advisor - Complete Documentation

## Table of Contents
1. [System Overview](#system-overview)
2. [Architecture & Flow](#architecture--flow)
3. [File Structure & Functionality](#file-structure--functionality)
4. [Execution Flow](#execution-flow)
5. [Code Breakdown by File](#code-breakdown-by-file)
6. [Data Flow Diagram](#data-flow-diagram)
7. [Key Concepts](#key-concepts)

---

## System Overview

### What is This Application?
A **multi-agent mutual fund recommendation system** that analyzes mutual funds from a local database and provides comprehensive investment advice through multiple specialized AI agents.

### Key Features:
- âœ… Local database only (3 sample funds)
- âœ… Multiple specialized AI agents (Risk, Return, Suitability, Macro)
- âœ… Semantic search using FAISS (vector database)
- âœ… OpenAI embeddings for fund matching
- âœ… Streamlit UI with accordion-based results
- âœ… Pre-configured fund recommendations

---

## Architecture & Flow

```
User Input (Fund Name)
       â†“
   app.py (Streamlit UI)
       â†“
orchestrator.py (Check fund exists & coordinate agents)
       â†“
   â”œâ”€â†’ check_fund_exists() [aggregator_agent.py]
   â”‚     (Uses FAISS to match fund)
   â”‚
   â””â”€â†’ If Fund Found:
       â”œâ”€â†’ risk_agent (LangChain)
       â”œâ”€â†’ return_agent (LangChain)
       â”œâ”€â†’ suitability_agent (LangChain)
       â”œâ”€â†’ macro_agent (LangChain)
       â””â”€â†’ aggregator_agent (Returns recommendation)
              â†“
         Results displayed in UI with accordions
```

---

## File Structure & Functionality

### ğŸ“ Project Structure
```
mutual_fund_multi_agent/
â”œâ”€â”€ app.py                          # Streamlit frontend
â”œâ”€â”€ orchestrator.py                 # Orchestration logic
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ .env                           # API keys
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ dummy_db_setup.py          # Initialize FAISS index
â”‚   â”œâ”€â”€ aggregator_agent.py        # Fund matching & final recommendation
â”‚   â”œâ”€â”€ risk_agent.py              # Risk analysis agent
â”‚   â”œâ”€â”€ return_agent.py            # Return analysis agent
â”‚   â”œâ”€â”€ suitability_agent.py       # Suitability analysis agent
â”‚   â”œâ”€â”€ macro_agent.py             # Macro outlook agent
â”‚   â”œâ”€â”€ unified_agent.py           # Alternative unified agent
â”‚   â”œâ”€â”€ funds.index                # FAISS vector index (generated)
â”‚   â””â”€â”€ funds_meta.npy             # Fund metadata (generated)
```

---

## Execution Flow

### Step 1: Application Startup
**File: `app.py`**
```python
import streamlit as st
from orchestrator import run_parallel_analysis

st.title("ğŸ“Š Parallel Multi-Agent Mutual Fund Advisor")
```
- Streamlit app initializes and displays the UI
- User sees text input box asking for fund name

### Step 2: User Input
**File: `app.py`**
```python
fund = st.text_input("Enter Mutual Fund Name", placeholder="e.g. Alpha Growth Fund")
```
- User types fund name (e.g., "Alpha Growth Fund")
- User clicks "Analyze Fund" button

### Step 3: Check if Fund Exists in Database
**File: `orchestrator.py` â†’ `aggregator_agent.py`**
```python
## orchestrator.py
fund_exists, matched_fund = check_fund_exists(fund_name, openai_client)

if not fund_exists:
    return None, f"No data found for '{fund_name}' in the local database..."
```

**Inside `check_fund_exists()` in `aggregator_agent.py`:**
1. Load FAISS index and fund metadata
2. Convert user input to embedding (using OpenAI)
3. Search for most similar fund in database
4. Check if similarity distance < 0.3 threshold
5. Return True/Fund data if match found, False if not

### Step 4: If Fund Found, Run Parallel Agents
**File: `orchestrator.py`**
```python
parallel_agents = RunnableParallel({
    "Risk Analysis": risk_agent(llm),
    "Return Analysis": return_agent(llm),
    "Suitability Analysis": suitability_agent(llm),
    "Macro Outlook": macro_agent(llm),
})

agent_outputs = parallel_agents.invoke({"fund": fund_name})
```

**What happens:** All 4 agents run simultaneously (parallel execution)

### Step 5: Get Final Recommendation
**File: `orchestrator.py` â†’ `aggregator_agent.py`**
```python
final_runnable = aggregator_agent(fund_name)
final_decision = final_runnable({"inputs": agent_outputs})
```

**Inside `aggregator_agent.py`:**
- Retrieves pre-configured recommendation from fund database
- Returns ONLY the recommendation (not the full analysis)

### Step 6: Display Results to User
**File: `app.py`**
```python
for agent_name, output in agent_results.items():
    with st.expander(f"ğŸ“‹ {agent_name}"):
        st.write(output.content)

st.subheader("ğŸ“Œ Final Recommendation")
st.success(final_decision)
```

Results displayed as:
- **Accordions:** Each agent's detailed analysis (expandable)
- **Final Recommendation:** Big success box with recommendation

---

## Code Breakdown by File

## 1ï¸âƒ£ app.py (Frontend)

**Purpose:** Streamlit user interface for the application

**Key Sections:**

```python
import streamlit as st
from orchestrator import run_parallel_analysis
```
- Import Streamlit for UI
- Import orchestrator to run analysis

```python
st.title("ğŸ“Š Parallel Multi-Agent Mutual Fund Advisor")
```
- Display main title

```python
fund = st.text_input(
    "Enter Mutual Fund Name",
    placeholder="e.g. Alpha Growth Fund"
)
```
- **Functionality:** Text input box for user to enter fund name
- **Output:** Returns string (fund name)

```python
if st.button("Analyze Fund"):
    if not fund.strip():
        st.warning("Please enter a mutual fund name.")
```
- **Functionality:** Button trigger for analysis
- **Validation:** Check if input is empty

```python
with st.spinner("Running Orchestrator analysis..."):
    agent_results, final_decision = run_parallel_analysis(fund)
```
- **Functionality:** Call orchestrator with fund name
- **Returns:** agent_results (dict) or None, final_decision (string)
- **UI:** Shows loading spinner while processing

```python
if agent_results is None:
    st.error(final_decision)
else:
    st.subheader("ğŸ” Agent Insights")
    
    for agent_name, output in agent_results.items():
        with st.expander(f"ğŸ“‹ {agent_name}"):
            st.write(output.content)
```
- **Functionality:** Display results
- **Logic:** 
  - If no fund found â†’ Show error message
  - If fund found â†’ Show accordions

```python
st.subheader("ğŸ“Œ Final Recommendation")
st.success(final_decision)
```
- Display final recommendation in green success box

---

## 2ï¸âƒ£ orchestrator.py (Orchestration Logic)

**Purpose:** Coordinates all agents and controls execution flow

**Key Functions:**

```python
def run_parallel_analysis(fund_name: str):
```
- **Input:** fund_name (string) - Name of fund to analyze
- **Output:** (agent_results, final_decision) tuple

**Step 1: Initialize OpenAI client**
```python
openai_client = OpenAI()
```

**Step 2: Check fund exists**
```python
fund_exists, matched_fund = check_fund_exists(fund_name, openai_client)

if not fund_exists:
    return None, f"No data found for '{fund_name}'..."
```
- **What it does:** 
  - Calls check_fund_exists() from aggregator_agent.py
  - Returns False if fund not in database
  - Prevents running agents for non-existent funds

**Step 3: Initialize LLM**
```python
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.2)
```
- **Model:** gpt-4o-mini (fast, cost-effective)
- **Temperature:** 0.2 (deterministic, focused responses)

**Step 4: Create parallel agents**
```python
parallel_agents = RunnableParallel({
    "Risk Analysis": risk_agent(llm),
    "Return Analysis": return_agent(llm),
    "Suitability Analysis": suitability_agent(llm),
    "Macro Outlook": macro_agent(llm),
})
```
- **Functionality:** Creates 4 agents that run simultaneously
- **Why parallel:** Faster execution (all agents run at same time)

**Step 5: Run agents**
```python
agent_outputs = parallel_agents.invoke({"fund": fund_name})
```
- **Input:** Dictionary with "fund" key containing fund name
- **Output:** Dictionary with 4 agent responses
- **Flow:** Each agent receives fund name and generates analysis

**Step 6: Get final recommendation**
```python
final_runnable = aggregator_agent(fund_name)
if isinstance(final_runnable, str):
    return agent_outputs, f"Aggregator agent error: {final_runnable}"
    
final_decision = final_runnable({"inputs": agent_outputs})
```
- **Functionality:** 
  - Create aggregator agent with fund name
  - Check if error occurred
  - If OK, call agent with all agent outputs
  - Get final recommendation

**Step 7: Return results**
```python
return agent_outputs, final_decision
```
- Returns to app.py for display

---

## 3ï¸âƒ£ agents/aggregator_agent.py (Fund Matching & Recommendation)

**Purpose:** Find fund in database and provide pre-configured recommendation

**Key Functions:**

### Function 1: load_faiss_index()
```python
def load_faiss_index():
    try:
        index = faiss.read_index("agents/funds.index")
        funds_meta = np.load("agents/funds_meta.npy", allow_pickle=True)
        return index, funds_meta
    except Exception as e:
        print(f"Error loading FAISS index or metadata: {e}")
        return None, None
```
- **Purpose:** Load vector database and fund metadata
- **Input:** None (reads from disk)
- **Output:** (index, funds_meta) or (None, None)
- **What it does:**
  - Loads FAISS index containing vector embeddings of funds
  - Loads numpy array with fund data (name, category, risk, etc.)
  - Returns None if file not found

**Important:** FAISS index is created by running `dummy_db_setup.py`

### Function 2: embed_query()
```python
def embed_query(query, openai_client):
    if not isinstance(query, str):
        query = str(query)
    response = openai_client.embeddings.create(
        input=query,
        model="text-embedding-ada-002"
    )
    return np.array(response.data[0].embedding, dtype=np.float32)
```
- **Purpose:** Convert text to vector embedding
- **Input:** query (string), openai_client
- **Output:** numpy array (1536 dimensions for ada-002)
- **What it does:**
  - Converts fund name string to OpenAI embedding
  - Returns 1536-dimensional vector

### Function 3: check_fund_exists()
```python
def check_fund_exists(query, openai_client):
    """Check if a fund exists in the local database based on similarity threshold."""
    index, funds_meta = load_faiss_index()
    if index is None or funds_meta is None:
        return False, None
    
    query_vec = embed_query(query, openai_client)
    D, I = index.search(np.expand_dims(query_vec, axis=0), k=1)
    
    DISTANCE_THRESHOLD = 0.3  # Very strict threshold
    best_distance = D[0][0]
    
    if best_distance <= DISTANCE_THRESHOLD:
        matched_fund = funds_meta[I[0][0]]
        return True, matched_fund
    else:
        return False, None
```

**Step by step:**
1. Load FAISS index and fund metadata
2. Convert user query to embedding
3. Search FAISS index for most similar fund
   - `index.search()` returns distances (D) and indices (I)
   - We get top 1 match
4. Check if distance is below threshold (0.3)
   - **Lower distance = better match**
   - **Threshold 0.3 is very strict** (rejects "Nippon India Small Cap")
5. Return True + fund data if match found, False if not

**Key insight:** This is how we ensure **no public data access** - only exact matches from local database

### Function 4: aggregator_agent()
```python
def aggregator_agent(query):
    load_dotenv()
    openai_api_key = os.getenv("OPENAI_API_KEY")
    openai_client = OpenAI(api_key=openai_api_key)
    index, funds_meta = load_faiss_index()
    
    if index is None or funds_meta is None:
        return "Error: FAISS index or metadata not found..."
    
    query_vec = embed_query(query, openai_client)
    D, I = index.search(np.expand_dims(query_vec, axis=0), k=1)
    
    retrieved_fund = funds_meta[I[0][0]]
    
    def aggregator_runnable(inputs):
        agent_outputs = inputs.get("inputs", {})
        fund_recommendation = retrieved_fund.get("recommendation", "No recommendation available")
        return fund_recommendation
    
    return aggregator_runnable
```

**What it does:**
1. Load OpenAI API key from .env
2. Load FAISS index
3. Search for fund in database
4. Returns a function (aggregator_runnable) that:
   - Takes agent outputs as input
   - Retrieves pre-configured recommendation from fund database
   - Returns ONLY the recommendation text

**Important:** Returns a **callable function**, not a string
- orchestrator.py will call this function later

---

## 4ï¸âƒ£ agents/risk_agent.py

**Purpose:** Analyze risk profile of fund

```python
from langchain_core.prompts import PromptTemplate

def risk_agent(llm):
    prompt = PromptTemplate(
        input_variables=["fund"],
        template="""
        You are a professional mutual fund risk analyst.

        Analyze the risk profile of the mutual fund: {fund}

        Consider volatility, drawdowns, and downside risk.
        Provide a concise investor-friendly assessment.
        """
    )
    return prompt | llm
```

**What it does:**
- Creates a prompt template with placeholder for fund name
- Returns a LangChain runnable (prompt | llm)
- When called with {"fund": "Alpha Growth Fund"}, it:
  1. Fills in the fund name in the prompt
  2. Sends prompt to LLM
  3. Returns LLM response about risk

**Output:** Detailed risk analysis (volatility, drawdowns, downside risk)

---

## 5ï¸âƒ£ agents/return_agent.py

**Purpose:** Analyze return characteristics

```python
def return_agent(llm):
    prompt = PromptTemplate(
        input_variables=["fund"],
        template="""
        You are a mutual fund performance analyst.

        Analyze the return characteristics of the mutual fund: {fund}

        Focus on consistency, CAGR quality, and risk-adjusted returns.
        """
    )
    return prompt | llm
```

**Output:** Analysis of consistency, CAGR, risk-adjusted returns

---

## 6ï¸âƒ£ agents/suitability_agent.py

**Purpose:** Identify suitable investor profiles

```python
def suitability_agent(llm):
    prompt = PromptTemplate(
        input_variables=["fund"],
        template="""
        You are an investment suitability advisor.

        Evaluate which investor profiles are suitable for the mutual fund: {fund}

        Consider risk appetite and investment horizon.
        """
    )
    return prompt | llm
```

**Output:** Suitable investor profiles based on risk and time horizon

---

## 7ï¸âƒ£ agents/macro_agent.py

**Purpose:** Analyze macro-economic impact

```python
def macro_agent(llm):
    prompt = PromptTemplate(
        input_variables=["fund"],
        template="""
        You are a macro-economic strategist.

        Analyze how current market and economic conditions
        impact the mutual fund: {fund}.
        """
    )
    return prompt | llm
```

**Output:** How economic conditions affect fund performance

---

## 8ï¸âƒ£ agents/dummy_db_setup.py (Initialize Database)

**Purpose:** Create FAISS vector index from fund data

**Key Functions:**

### Function 1: get_fund_vector()
```python
def get_fund_vector(fund, openai_client):
    desc = f"{fund['name']} {fund['category']} {fund['risk']} {fund['returns']} {fund['suitability']} {fund['macro']}"
    if not isinstance(desc, str):
        desc = str(desc)
    response = openai_client.embeddings.create(
        input=desc,
        model="text-embedding-ada-002"
    )
    return np.array(response.data[0].embedding, dtype=np.float32)
```
- **Purpose:** Convert fund description to embedding vector
- **What it does:**
  1. Create fund description from properties
  2. Call OpenAI to get embedding
  3. Return as numpy array

### Function 2: create_faiss_index()
```python
def create_faiss_index():
    openai_api_key = os.getenv("OPENAI_API_KEY")
    openai_client = OpenAI(api_key=openai_api_key)
    dim = 1536  # Embedding dimension for ada-002
    index = faiss.IndexFlatL2(dim)
    vectors = []
    
    for fund in funds:
        vec = get_fund_vector(fund, openai_client)
        vectors.append(vec)
    
    vectors_np = np.vstack(vectors)
    index.add(vectors_np)
    
    os.makedirs("agents", exist_ok=True)
    faiss.write_index(index, "agents/funds.index")
    np.save("agents/funds_meta.npy", funds)
    print("FAISS index and metadata saved in agents/.")
```

**Step by step:**
1. Load OpenAI API key
2. Create FAISS index (L2 distance, 1536 dimensions)
3. For each fund:
   - Convert to embedding
   - Add to vectors list
4. Combine all vectors into one numpy array
5. Add all vectors to FAISS index
6. Save index to "agents/funds.index"
7. Save fund metadata to "agents/funds_meta.npy"

**When to run:** Run once to initialize, or whenever you add new funds

**Run command:** `python agents/dummy_db_setup.py`

---

## 9ï¸âƒ£ Dummy Fund Data (In dummy_db_setup.py)

```python
funds = [
    {
        "name": "Alpha Growth Fund",
        "category": "Equity",
        "risk": "High",
        "returns": 12.5,
        "suitability": "Aggressive",
        "macro": "Positive macro outlook",
        "recommendation": "Strong Buy for next 5 years"
    },
    {
        "name": "Beta Income Fund",
        "category": "Debt",
        "risk": "Low",
        "returns": 7.2,
        "suitability": "Conservative",
        "macro": "Stable macro environment",
        "recommendation": "Buy for next 5 years with only 8% return expectation"
    },
    {
        "name": "Gamma Balanced Fund",
        "category": "Hybrid",
        "risk": "Medium",
        "returns": 9.8,
        "suitability": "Moderate",
        "macro": "Neutral macro factors",
        "recommendation": "Sell/Don't buy as it is continuously under performing the benchmark in last 5 years"
    }
]
```

**Properties:**
- `name`: Fund name (for semantic search)
- `category`: Type of fund (Equity, Debt, Hybrid)
- `risk`: Risk level (High, Low, Medium)
- `returns`: Expected return percentage
- `suitability`: Target investor profile
- `macro`: Macro outlook
- `recommendation`: Pre-configured recommendation (display in UI)

---

## Data Flow Diagram

```
INITIALIZATION PHASE:
â”‚
â”œâ”€ funds = [3 fund objects from dummy_db_setup.py]
â”‚
â”œâ”€ dummy_db_setup.py runs (one time setup)
â”‚   â”œâ”€ For each fund:
â”‚   â”‚   â”œâ”€ Create description: "Alpha Growth Fund Equity High 12.5 Aggressive..."
â”‚   â”‚   â”œâ”€ Send to OpenAI API
â”‚   â”‚   â””â”€ Get 1536-dimensional embedding
â”‚   â”‚
â”‚   â”œâ”€ Store embeddings in FAISS index
â”‚   â”œâ”€ Save as agents/funds.index
â”‚   â”œâ”€ Save metadata as agents/funds_meta.npy
â”‚

RUNTIME PHASE (Each time user queries):
â”‚
â”œâ”€ User enters: "Alpha Growth Fund"
â”‚
â”œâ”€ app.py calls: run_parallel_analysis("Alpha Growth Fund")
â”‚
â”œâ”€ orchestrator.py:
â”‚   â”‚
â”‚   â”œâ”€ Check fund exists:
â”‚   â”‚   â”œâ”€ Convert "Alpha Growth Fund" to embedding
â”‚   â”‚   â”œâ”€ Search FAISS index (k=1)
â”‚   â”‚   â”œâ”€ Get best match distance
â”‚   â”‚   â””â”€ If distance < 0.3: FOUND âœ“ else: NOT FOUND âœ—
â”‚   â”‚
â”‚   â”œâ”€ If FOUND, Initialize LangChain LLM
â”‚   â”‚
â”‚   â”œâ”€ Run Parallel Agents (all at same time):
â”‚   â”‚   â”œâ”€ Risk Agent â†’ "Analyze risk of Alpha Growth Fund"
â”‚   â”‚   â”œâ”€ Return Agent â†’ "Analyze returns of Alpha Growth Fund"
â”‚   â”‚   â”œâ”€ Suitability Agent â†’ "Analyze suitability of Alpha Growth Fund"
â”‚   â”‚   â””â”€ Macro Agent â†’ "Analyze macro impact on Alpha Growth Fund"
â”‚   â”‚
â”‚   â”œâ”€ Each agent sends to OpenAI GPT-4o-mini
â”‚   â”œâ”€ Get 4 detailed analyses
â”‚   â”‚
â”‚   â”œâ”€ Get Final Recommendation:
â”‚   â”‚   â”œâ”€ aggregator_agent returns "Strong Buy for next 5 years"
â”‚   â”‚   â””â”€ (From fund.recommendation property, NOT from LLM)
â”‚   â”‚
â”‚   â””â”€ Return to app.py
â”‚
â”œâ”€ app.py displays results:
â”‚   â”œâ”€ Accordions (expandable):
â”‚   â”‚   â”œâ”€ Risk Analysis (from risk_agent)
â”‚   â”‚   â”œâ”€ Return Analysis (from return_agent)
â”‚   â”‚   â”œâ”€ Suitability Analysis (from suitability_agent)
â”‚   â”‚   â””â”€ Macro Outlook (from macro_agent)
â”‚   â”‚
â”‚   â””â”€ Final Recommendation (green box):
â”‚       â””â”€ "Strong Buy for next 5 years"
```

---

## Key Concepts

### 1. FAISS (Facebook AI Similarity Search)
**What:** Vector database for fast similarity search
**Why:** Fast semantic search through embeddings
**How in our app:**
- Fund names get converted to 1536-dim vectors
- User query gets converted to same vector space
- FAISS finds most similar fund
- Distance threshold (0.3) ensures only exact matches

### 2. OpenAI Embeddings
**What:** Convert text to numerical vectors
**Model:** text-embedding-ada-002 (1536 dimensions)
**Used for:**
- Converting fund names to vectors (in dummy_db_setup.py)
- Converting user query to vector (in check_fund_exists)
- Semantic matching without keyword search

### 3. LangChain
**What:** Framework for building chains with LLMs
**Used for:**
- Creating prompt templates (agents)
- Running agents in parallel (RunnableParallel)
- Invoking LLM with structured prompts

### 4. Distance Threshold (0.3)
**Why so strict?**
- Prevents false matches
- Ensures "Nippon India Small Cap" doesn't match "Alpha Growth Fund"
- Returns "no data found" for queries not in database

**How it works:**
- L2 distance measured between embedding vectors
- If best_distance > 0.3 â†’ NOT a match â†’ "no data found"
- If best_distance â‰¤ 0.3 â†’ IS a match â†’ run agents

### 5. Parallel Execution
**Why parallel?**
- All 4 agents run simultaneously (not sequentially)
- Faster overall execution time
- Independent analyses (one agent doesn't depend on others)

**How it works:**
```python
RunnableParallel({
    "Risk Analysis": risk_agent(llm),
    "Return Analysis": return_agent(llm),
    "Suitability Analysis": suitability_agent(llm),
    "Macro Outlook": macro_agent(llm),
})
```

### 6. Pre-configured Recommendations
**Why not use LLM for final recommendation?**
- Recommendations are expert-verified
- Consistent and reliable
- Faster (no API call needed)
- More trustworthy

**Where stored:** In fund object's "recommendation" property

---

## Important Code Lines & What They Do

### Line 1: Load environment variables
```python
from dotenv import load_dotenv
load_dotenv()
```
**What:** Reads .env file to load OPENAI_API_KEY

### Line 2: Initialize OpenAI client
```python
openai_client = OpenAI(api_key=openai_api_key)
```
**What:** Creates client to call OpenAI API

### Line 3: Load FAISS index
```python
index = faiss.read_index("agents/funds.index")
```
**What:** Loads pre-built vector index from disk

### Line 4: Search FAISS
```python
D, I = index.search(np.expand_dims(query_vec, axis=0), k=1)
```
**What:** 
- D = distances (how similar)
- I = indices (which fund)
- k=1 = get top 1 match

### Line 5: Get distance
```python
best_distance = D[0][0]
```
**What:** Extract distance of top match

### Line 6: Check threshold
```python
if best_distance <= DISTANCE_THRESHOLD:
```
**What:** Only proceed if fund is similar enough

### Line 7: Create parallel agents
```python
parallel_agents = RunnableParallel({...})
```
**What:** All agents run simultaneously

### Line 8: Invoke agents
```python
agent_outputs = parallel_agents.invoke({"fund": fund_name})
```
**What:** Send fund name to all agents, get results

### Line 9: Display accordions
```python
with st.expander(f"ğŸ“‹ {agent_name}"):
```
**What:** Makes each agent output expandable

---

## Setup Instructions

### 1. Create Virtual Environment
```bash
python -m venv venv
venv\Scripts\activate
```

### 2. Install Requirements
```bash
pip install -r requirements.txt
```

### 3. Set Environment Variables
Create `.env` file:
```
OPENAI_API_KEY=sk-your-key-here
```

### 4. Initialize Database
```bash
python agents/dummy_db_setup.py
```
**Output:** 
- agents/funds.index
- agents/funds_meta.npy

### 5. Run Application
```bash
streamlit run app.py
```

---

## Execution Summary

```
User Query: "Alpha Growth Fund"
     â†“ 
app.py: Takes input, calls orchestrator
     â†“
orchestrator.py: Checks if fund exists via FAISS
     â†“
Is Fund in Database? (distance < 0.3)
     â”œâ”€ NO â†’ Return "No data found" message
     â””â”€ YES â†’ Continue to agents
               â†“
        Run 4 agents in parallel:
        â”œâ”€ Risk Analysis
        â”œâ”€ Return Analysis
        â”œâ”€ Suitability Analysis
        â””â”€ Macro Outlook
               â†“
        Aggregator gets pre-configured recommendation
               â†“
app.py: Display results with accordions + recommendation
```

---

## Summary

This is a **production-grade multi-agent system** that:

âœ… **Uses local database only** (3 sample funds via FAISS)
âœ… **Prevents hallucination** (strict distance threshold)
âœ… **Runs multiple analyses in parallel** (faster execution)
âœ… **Provides structured output** (accordions for different perspectives)
âœ… **Uses pre-verified recommendations** (data-driven, not LLM-generated)
âœ… **Clean separation of concerns** (each agent has specific role)
âœ… **Scalable architecture** (easy to add more agents or funds)

---

## Future Enhancements

1. **Add more funds** to dummy_db_setup.py
2. **Connect to real database** instead of local files
3. **Add user preferences** (risk tolerance, time horizon)
4. **Personalized recommendations** based on user profile
5. **Performance tracking** of recommendations over time
6. **Portfolio analysis** (multiple fund combinations)
7. **Real-time fund data** integration

---

**Created:** February 2026
**Technology Stack:** Python, LangChain, OpenAI, FAISS, Streamlit
